{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio requests openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pht1QiEIKNkh",
        "outputId": "e75dc2b0-ed8f-4b7e-a3d0-aa46fbe26fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.104.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "kbea1zOhKFI_",
        "outputId": "96425621-d2cd-4323-c9ea-84e79c62573f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a92e96b5beca78330b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a92e96b5beca78330b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import shlex\n",
        "import textwrap\n",
        "from typing import Optional, Dict, Any, Tuple\n",
        "\n",
        "try:\n",
        "    import openai\n",
        "except Exception:\n",
        "    openai = None\n",
        "\n",
        "import requests\n",
        "import gradio as gr\n",
        "\n",
        "OPENAI_API_KEY = os.environ.get(\"OPEN AI API KEY\")\n",
        "OPENAI_MODEL = os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
        "if OPENAI_API_KEY and openai is not None:\n",
        "    try:\n",
        "        openai.api_key = OPENAI_API_KEY\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def mask_token(token: str) -> str:\n",
        "    if not token:\n",
        "        return token\n",
        "    if len(token) <= 8:\n",
        "        return \"*\" * len(token)\n",
        "    return token[:4] + \"...\" + token[-4:]\n",
        "\n",
        "def build_parser_prompt(instruction: str) -> str:\n",
        "    examples = [\n",
        "        {\n",
        "            \"instr\": \"Test a GET request to https://api.example.com/users with token abc123\",\n",
        "            \"json\": {\n",
        "                \"method\": \"GET\",\n",
        "                \"url\": \"https://api.example.com/users\",\n",
        "                \"headers\": {\"Authorization\": \"Bearer abc123\"},\n",
        "                \"auth\": {\"type\": \"bearer\", \"token\": \"abc123\"},\n",
        "                \"body\": None,\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"instr\": \"Send a POST to /login with JSON {\\\"user\\\":\\\"alice\\\",\\\"pass\\\":\\\"mypassword\\\"}\",\n",
        "            \"json\": {\n",
        "                \"method\": \"POST\",\n",
        "                \"url\": \"/login\",\n",
        "                \"headers\": {\"Content-Type\": \"application/json\"},\n",
        "                \"auth\": None,\n",
        "                \"body\": {\"user\": \"alice\", \"pass\": \"mypassword\"},\n",
        "            },\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    prompt = textwrap.dedent(\n",
        "        \"\"\"\n",
        "You are a strict parser that converts a developer's natural-language instruction into a JSON object only. Output JSON with exact keys: method, url, headers, auth, body. Do not output explanatory text.\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    for ex in examples:\n",
        "        prompt += \"INSTRUCTION: \" + ex[\"instr\"] + \"\\n\"\n",
        "        prompt += \"JSON: \" + json.dumps(ex[\"json\"]) + \"\\n\\n\"\n",
        "\n",
        "    prompt += \"INSTRUCTION: \" + instruction + \"\\n\"\n",
        "    prompt += \"JSON: \"\n",
        "    return prompt\n",
        "\n",
        "def _extract_message_text_from_openai_response(resp: Any) -> Optional[str]:\n",
        "    try:\n",
        "        if isinstance(resp, dict):\n",
        "            choices = resp.get(\"choices\") or []\n",
        "        else:\n",
        "            choices = getattr(resp, \"choices\", [])\n",
        "        if not choices:\n",
        "            return None\n",
        "        first = choices[0]\n",
        "        if isinstance(first, dict):\n",
        "            msg = first.get(\"message\")\n",
        "            if isinstance(msg, dict):\n",
        "                return msg.get(\"content\")\n",
        "            return first.get(\"text\")\n",
        "        else:\n",
        "            if hasattr(first, \"message\"):\n",
        "                return getattr(first.message, \"content\", None)\n",
        "            return getattr(first, \"text\", None)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def extract_json_from_text(text: str) -> Optional[Dict[str, Any]]:\n",
        "    if not isinstance(text, str):\n",
        "        return None\n",
        "    s = text.strip()\n",
        "    start = s.find('{')\n",
        "    if start == -1:\n",
        "        try:\n",
        "            return json.loads(s)\n",
        "        except Exception:\n",
        "            return None\n",
        "    stack = []\n",
        "    for i in range(start, len(s)):\n",
        "        c = s[i]\n",
        "        if c == '{':\n",
        "            stack.append(i)\n",
        "        elif c == '}':\n",
        "            stack.pop()\n",
        "            if not stack:\n",
        "                candidate = s[start:i+1]\n",
        "                try:\n",
        "                    return json.loads(candidate)\n",
        "                except Exception:\n",
        "                    break\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def call_llm_parser(instruction: str, model: str = OPENAI_MODEL) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:\n",
        "    if openai is None or OPENAI_API_KEY is None:\n",
        "        return None, \"OpenAI not configured.\"\n",
        "    prompt = build_parser_prompt(instruction)\n",
        "    try:\n",
        "        if hasattr(openai, \"ChatCompletion\"):\n",
        "            resp = openai.ChatCompletion.create(model=model, messages=[{\"role\": \"system\", \"content\": \"You are a parser that outputs only JSON.\"}, {\"role\": \"user\", \"content\": prompt}], temperature=0.0, max_tokens=500)\n",
        "        elif hasattr(openai, \"Completion\"):\n",
        "            resp = openai.Completion.create(model=model, prompt=prompt, temperature=0.0, max_tokens=500)\n",
        "        else:\n",
        "            return None, \"No supported OpenAI client interface found.\"\n",
        "        text = _extract_message_text_from_openai_response(resp)\n",
        "        if not text:\n",
        "            return None, \"LLM returned empty response\"\n",
        "        parsed = extract_json_from_text(text)\n",
        "        if parsed is None:\n",
        "            return None, f\"LLM returned unparsable JSON: {text[:200]}\"\n",
        "        return parsed, text\n",
        "    except Exception as e:\n",
        "        return None, str(e)\n",
        "\n",
        "def fallback_parse(instruction: str) -> Dict[str, Any]:\n",
        "    inst = instruction.strip()\n",
        "    method = \"GET\"\n",
        "    m = re.search(r\"\\b(GET|POST|PUT|DELETE|PATCH|OPTIONS|HEAD)\\b\", inst, re.IGNORECASE)\n",
        "    if m:\n",
        "        method = m.group(1).upper()\n",
        "    url = \"\"\n",
        "    u = re.search(r\"https?://[\\w\\-\\._~:/?#\\[\\]@!$&'()*+,;=%]+\", inst)\n",
        "    if u:\n",
        "        url = u.group(0)\n",
        "    else:\n",
        "        p = re.search(r\"(/[-\\w@:\\.%_\\+~#=\\/{}]+)\", inst)\n",
        "        if p:\n",
        "            url = p.group(1)\n",
        "    headers = {}\n",
        "    auth = None\n",
        "    tok = None\n",
        "    m_tok = re.search(r\"token\\s*[:=]?\\s*([A-Za-z0-9\\-\\._~\\+\\/=]+)\", inst, re.IGNORECASE)\n",
        "    if m_tok:\n",
        "        tok = m_tok.group(1)\n",
        "        auth = {\"type\": \"bearer\", \"token\": tok}\n",
        "        headers[\"Authorization\"] = f\"Bearer {tok}\"\n",
        "    else:\n",
        "        m_apikey = re.search(r\"api[-_ ]?key\\s*[:=]?\\s*([A-Za-z0-9\\-\\._~\\+\\/=]+)\", inst, re.IGNORECASE)\n",
        "        if m_apikey:\n",
        "            tok = m_apikey.group(1)\n",
        "            auth = {\"type\": \"api_key\", \"token\": tok}\n",
        "            headers[\"Authorization\"] = f\"ApiKey {tok}\"\n",
        "    body = None\n",
        "    json_region = None\n",
        "    j = re.search(r\"(\\{[\\s\\S]*\\})\", inst)\n",
        "    if j:\n",
        "        json_region = j.group(1)\n",
        "        try:\n",
        "            body = json.loads(json_region)\n",
        "            headers.setdefault(\"Content-Type\", \"application/json\")\n",
        "        except Exception:\n",
        "            body = json_region\n",
        "            headers.setdefault(\"Content-Type\", \"text/plain\")\n",
        "    header_pattern = re.compile(r\"([A-Za-z-]+)\\s*:\\s*([^,;\\n]+)\")\n",
        "    for header_match in header_pattern.finditer(inst):\n",
        "        k = header_match.group(1).strip()\n",
        "        v = header_match.group(2).strip()\n",
        "        if json_region and header_match.start() >= inst.find(json_region) and header_match.end() <= inst.find(json_region) + len(json_region):\n",
        "            continue\n",
        "        if k.lower() == \"authorization\":\n",
        "            headers[\"Authorization\"] = v\n",
        "        else:\n",
        "            headers[k] = v\n",
        "    return {\"method\": method, \"url\": url, \"headers\": headers, \"auth\": auth, \"body\": body}\n",
        "\n",
        "def build_curl(parsed: Dict[str, Any]) -> str:\n",
        "    method = parsed.get(\"method\", \"GET\").upper()\n",
        "    url = parsed.get(\"url\", \"\")\n",
        "    headers = parsed.get(\"headers\") or {}\n",
        "    body = parsed.get(\"body\")\n",
        "    parts = [\"curl\"]\n",
        "    parts.extend([\"-X\", shlex.quote(method)])\n",
        "    for k, v in headers.items():\n",
        "        parts.extend([\"-H\", shlex.quote(f\"{k}: {v}\")])\n",
        "    if body is not None:\n",
        "        if isinstance(body, (dict, list)):\n",
        "            body_str = json.dumps(body)\n",
        "        else:\n",
        "            body_str = str(body)\n",
        "        parts.extend([\"-d\", shlex.quote(body_str)])\n",
        "    parts.append(shlex.quote(url))\n",
        "    return \" \\\\\\n\".join(parts)\n",
        "\n",
        "def run_request(parsed: Dict[str, Any], timeout: int = 10) -> Tuple[int, Dict[str, Any], str]:\n",
        "    url = parsed.get(\"url\")\n",
        "    method = parsed.get(\"method\", \"GET\").upper()\n",
        "    headers = parsed.get(\"headers\") or {}\n",
        "    body = parsed.get(\"body\")\n",
        "    if not url:\n",
        "        return 0, {}, \"Missing URL\"\n",
        "    if url.startswith(\"/\"):\n",
        "        return 0, {}, \"URL appears to be a path only. Provide a full URL including scheme and host.\"\n",
        "    try:\n",
        "        if body is None:\n",
        "            resp = requests.request(method, url, headers=headers, timeout=timeout)\n",
        "        else:\n",
        "            if isinstance(body, (dict, list)):\n",
        "                resp = requests.request(method, url, headers=headers, json=body, timeout=timeout)\n",
        "            else:\n",
        "                resp = requests.request(method, url, headers=headers, data=str(body), timeout=timeout)\n",
        "        result_headers = dict(resp.headers)\n",
        "        try:\n",
        "            result_body = resp.json()\n",
        "            body_text = json.dumps(result_body, indent=2)\n",
        "        except Exception:\n",
        "            body_text = resp.text\n",
        "        return resp.status_code, result_headers, body_text\n",
        "    except Exception as e:\n",
        "        return 0, {}, str(e)\n",
        "\n",
        "def generate_request_from_instruction(instruction: str) -> Tuple[Dict[str, Any], str, str]:\n",
        "    if not instruction or not instruction.strip():\n",
        "        return {}, \"\", \"Please provide an instruction.\"\n",
        "    if OPENAI_API_KEY and openai is not None:\n",
        "        parsed, raw = call_llm_parser(instruction)\n",
        "        if parsed:\n",
        "            curl = build_curl(parsed)\n",
        "            parsed_display = json.loads(json.dumps(parsed))\n",
        "            if parsed_display.get(\"auth\") and parsed_display[\"auth\"].get(\"token\"):\n",
        "                parsed_display[\"auth\"][\"token\"] = mask_token(parsed_display[\"auth\"][\"token\"])\n",
        "            return parsed_display, curl, \"Parsed with LLM\"\n",
        "    parsed = fallback_parse(instruction)\n",
        "    curl = build_curl(parsed)\n",
        "    parsed_display = json.loads(json.dumps(parsed))\n",
        "    if parsed_display.get(\"auth\") and parsed_display[\"auth\"].get(\"token\"):\n",
        "        parsed_display[\"auth\"][\"token\"] = mask_token(parsed_display[\"auth\"][\"token\"])\n",
        "    return parsed_display, curl, \"Parsed with fallback rule-based parser\"\n",
        "\n",
        "EXAMPLES = [\n",
        "    \"Test a GET request to https://api.example.com/users with token abc123\",\n",
        "    \"Send a POST to /login with JSON {\\\"user\\\":\\\"alice\\\",\\\"pass\\\":\\\"mypassword\\\"}\",\n",
        "    \"Test GET /profile with API key=XYZ and header Accept: application/xml\",\n",
        "]\n",
        "\n",
        "def build_ui() -> gr.Blocks:\n",
        "    with gr.Blocks(title=\"API Test — Request Setup Automation\") as demo:\n",
        "        gr.Markdown(\"# API Test — Request Setup Automation\")\n",
        "        gr.Markdown(\"Describe the API request you want and the assistant will generate a structured request and a cURL command.\")\n",
        "        with gr.Row():\n",
        "            inp = gr.Textbox(label=\"Instruction\", placeholder='e.g. Send a POST to /login with JSON {\"user\":\"alice\"}', lines=3)\n",
        "            with gr.Column(scale=1):\n",
        "                gen_btn = gr.Button(\"Generate Request\")\n",
        "                run_btn = gr.Button(\"Run Request\")\n",
        "                export_dropdown = gr.Dropdown(choices=[\"cURL\", \"Postman (raw JSON)\"], value=\"cURL\", label=\"Export as\")\n",
        "        with gr.Row():\n",
        "            parsed_out = gr.JSON(label=\"Structured Request\")\n",
        "            curl_out = gr.Textbox(label=\"cURL / Export\", lines=5)\n",
        "        status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "        response_box = gr.Textbox(label=\"Live Response (if run)\", lines=10, interactive=False)\n",
        "        gr.Examples(examples=EXAMPLES, inputs=inp)\n",
        "        def on_generate(instruction: str):\n",
        "            parsed, curl, status_msg = generate_request_from_instruction(instruction)\n",
        "            return parsed, curl, status_msg\n",
        "        gen_btn.click(on_generate, inputs=[inp], outputs=[parsed_out, curl_out, status])\n",
        "        def on_run(parsed_json):\n",
        "            if not parsed_json:\n",
        "                return \"\", \"No parsed request to run. Generate one first.\"\n",
        "            try:\n",
        "                status_code, resp_headers, body_text = run_request(parsed_json)\n",
        "                if status_code == 0:\n",
        "                    return \"\", f\"Request failed: {body_text}\"\n",
        "                resp_display = f\"Status: {status_code}\\nHeaders: {json.dumps(resp_headers, indent=2)}\\nBody:\\n{body_text}\"\n",
        "                return \"Ran request successfully.\", resp_display\n",
        "            except Exception as e:\n",
        "                return \"\", f\"Error running request: {str(e)}\"\n",
        "        run_btn.click(on_run, inputs=[parsed_out], outputs=[status, response_box])\n",
        "    return demo\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo = build_ui()\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k1VRMhbWM8BF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}